{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54554,
     "status": "ok",
     "timestamp": 1556730084170,
     "user": {
      "displayName": "Vikram Agarwal",
      "photoUrl": "",
      "userId": "06418374386143732359"
     },
     "user_tz": 420
    },
    "id": "yk7nUSKYatkN",
    "outputId": "790c98c8-590e-48fa-a41b-0eb2b2e8c9fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagar/predict_expression\n"
     ]
    }
   ],
   "source": [
    "%cd /home/vagar/predict_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGY4mlca0KST"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round1\n",
      "-10000\n",
      "(19071, 2002)\n",
      "-9800\n",
      "(38142, 2002)\n",
      "-9600\n",
      "(57213, 2002)\n",
      "-9400\n",
      "(76284, 2002)\n",
      "-9200\n",
      "(95355, 2002)\n",
      "-9000\n",
      "(114426, 2002)\n",
      "-8800\n",
      "(133497, 2002)\n",
      "-8600\n",
      "(152568, 2002)\n",
      "-8400\n",
      "(171639, 2002)\n",
      "-8200\n",
      "(190710, 2002)\n",
      "-8000\n",
      "(209781, 2002)\n",
      "-7800\n",
      "(228852, 2002)\n",
      "-7600\n",
      "(247923, 2002)\n",
      "-7400\n",
      "(266994, 2002)\n",
      "-7200\n",
      "(286065, 2002)\n",
      "-7000\n",
      "(305136, 2002)\n",
      "-6800\n",
      "(324207, 2002)\n",
      "-6600\n",
      "(343278, 2002)\n",
      "-6400\n",
      "(362349, 2002)\n",
      "-6200\n",
      "(381420, 2002)\n",
      "-6000\n",
      "(400491, 2002)\n",
      "-5800\n",
      "(419562, 2002)\n",
      "-5600\n",
      "(438633, 2002)\n",
      "-5400\n",
      "(457704, 2002)\n",
      "-5200\n",
      "(476775, 2002)\n",
      "-5000\n",
      "(495846, 2002)\n",
      "-4800\n",
      "(514917, 2002)\n",
      "-4600\n",
      "(533988, 2002)\n",
      "-4400\n",
      "(553059, 2002)\n",
      "-4200\n",
      "(572130, 2002)\n",
      "-4000\n",
      "(591201, 2002)\n",
      "-3800\n",
      "(610272, 2002)\n",
      "-3600\n",
      "(629343, 2002)\n",
      "-3400\n",
      "(648414, 2002)\n",
      "-3200\n",
      "(667485, 2002)\n",
      "-3000\n",
      "(686556, 2002)\n",
      "-2800\n",
      "(705627, 2002)\n",
      "-2600\n",
      "(724698, 2002)\n",
      "-2400\n",
      "(743769, 2002)\n",
      "-2200\n",
      "(762840, 2002)\n",
      "-2000\n",
      "(781911, 2002)\n",
      "-1800\n",
      "(800982, 2002)\n",
      "-1600\n",
      "(820053, 2002)\n",
      "-1400\n",
      "(839124, 2002)\n",
      "-1200\n",
      "(858195, 2002)\n",
      "-1000\n",
      "(877266, 2002)\n",
      "-800\n",
      "(896337, 2002)\n",
      "-600\n",
      "(915408, 2002)\n",
      "-400\n",
      "(934479, 2002)\n",
      "-200\n",
      "(953550, 2002)\n",
      "0\n",
      "(972621, 2002)\n",
      "200\n",
      "(991692, 2002)\n",
      "400\n",
      "(1010763, 2002)\n",
      "600\n",
      "(1029834, 2002)\n",
      "800\n",
      "(1048905, 2002)\n",
      "1000\n",
      "(1067976, 2002)\n",
      "1200\n",
      "(1087047, 2002)\n",
      "1400\n",
      "(1106118, 2002)\n",
      "1600\n",
      "(1125189, 2002)\n",
      "1800\n",
      "(1144260, 2002)\n",
      "2000\n",
      "(1163331, 2002)\n",
      "2200\n",
      "(1182402, 2002)\n",
      "2400\n",
      "(1201473, 2002)\n",
      "2600\n",
      "(1220544, 2002)\n",
      "2800\n",
      "(1239615, 2002)\n",
      "3000\n",
      "(1258686, 2002)\n",
      "3200\n",
      "(1277757, 2002)\n",
      "3400\n",
      "(1296828, 2002)\n",
      "3600\n",
      "(1315899, 2002)\n",
      "3800\n",
      "(1334970, 2002)\n",
      "4000\n",
      "(1354041, 2002)\n",
      "4200\n",
      "(1373112, 2002)\n",
      "4400\n",
      "(1392183, 2002)\n",
      "4600\n",
      "(1411254, 2002)\n",
      "4800\n",
      "(1430325, 2002)\n",
      "5000\n",
      "(1449396, 2002)\n",
      "5200\n",
      "(1468467, 2002)\n",
      "5400\n",
      "(1487538, 2002)\n",
      "5600\n",
      "(1506609, 2002)\n",
      "5800\n",
      "(1525680, 2002)\n",
      "6000\n",
      "(1544751, 2002)\n",
      "6200\n",
      "(1563822, 2002)\n",
      "6400\n",
      "(1582893, 2002)\n",
      "6600\n",
      "(1601964, 2002)\n",
      "6800\n",
      "(1621035, 2002)\n",
      "7000\n",
      "(1640106, 2002)\n",
      "7200\n",
      "(1659177, 2002)\n",
      "7400\n",
      "(1678248, 2002)\n",
      "7600\n",
      "(1697319, 2002)\n",
      "7800\n",
      "(1716390, 2002)\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "import os, h5py\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import reduce\n",
    "\n",
    "maxshift = 10000\n",
    "X = np.array([])\n",
    "\n",
    "print(\"Round1\")\n",
    "for shift in list(range(-maxshift, maxshift + 1, 200)):\n",
    "    print(shift)\n",
    "    preds = h5py.File(\"embedded_vals/human_hg19_promoters_1nt_FantomCorrected.bed.shift_SHIFT.h5\".replace(\n",
    "        'SHIFT', str(shift)), 'r')['/pred']\n",
    "    X = np.concatenate([X,preds]) if X.size else preds\n",
    "    print(X.shape)\n",
    "\n",
    "print(\"Fitting PCA\")\n",
    "pca = PCA(0.99, whiten=True) #Incremental, batch_size=10\n",
    "X = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "maxshift = 100000\n",
    "X = np.array([])\n",
    "print(\"Round2\")\n",
    "for shift in list(range(-maxshift, maxshift + 1, 200)):\n",
    "    print(shift)\n",
    "    preds = h5py.File(\"embedded_vals/human_hg19_promoters_1nt_FantomCorrected.bed.shift_SHIFT.h5\".replace(\n",
    "        'SHIFT', str(shift)), 'r')['/pred']\n",
    "    preds = pca.transform(preds)\n",
    "    preds = np.expand_dims(preds,axis=1)\n",
    "    X = np.hstack([X,preds]) if X.size else preds\n",
    "    print(X.shape)\n",
    "\n",
    "f = h5py.File('embedded_vals/X.h5', 'w')\n",
    "f.create_dataset('pred', data=X)\n",
    "f.close()\n",
    "\n",
    "compress_args = {'compression': 'gzip', 'compression_opts': 1}\n",
    "out_dir=\"prepared_data\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "outfile = os.path.join(out_dir, 'expr_preds.h5')\n",
    "\n",
    "genes = pd.read_csv(\"human_hg19_promoters_1nt_FantomCorrected.bed\",\n",
    "                    sep=\"\\t\", header=None, names=['chr', 'start', 'end', '.', 'strand', '?', '??', '???', 'name'])\n",
    "X = X[~genes.chr.isin(['chrY']),:,:]\n",
    "genes = genes[~genes.chr.isin(['chrY'])] #'chrX',\n",
    "y = pd.read_csv(\"57epigenomes.RPKM.pc\", sep=\"\\t\", index_col=0)\n",
    "maskedIDs = pd.read_table(\"mask_histone_genes.txt\", header=None) #mask histone genes, chrY genes already filtered out\n",
    "y = y[y.index.isin(genes['name']) & ~y.index.isin(maskedIDs[0])] #remove rows corresponding to chrY or histone sequences\n",
    "X = X[genes['name'].isin(y.index),:,:]\n",
    "genes = genes[genes['name'].isin(y.index)]\n",
    "y = reduce(pd.DataFrame.append, map(lambda i: y[y.index == i], genes['name']))\n",
    "\n",
    "# print X.shape, y.shape, genes.shape #np.swapaxes(X,1,2)\n",
    "y = preprocessing.scale(np.log10(y+0.1))\n",
    "idxs = np.arange(X.shape[0])\n",
    "npr.seed(0)\n",
    "npr.shuffle(idxs)\n",
    "\n",
    "geneNames = np.array(genes[genes.columns[8]])[idxs]\n",
    "X = X[idxs]\n",
    "y = y[idxs]\n",
    "\n",
    "# check that the sum is valid\n",
    "test_count = 1000\n",
    "valid_count = 1000\n",
    "assert(test_count + valid_count <= X.shape[0])\n",
    "train_count = X.shape[0] - test_count - valid_count\n",
    "\n",
    "print('%d training sequences ' % train_count)\n",
    "print('%d test sequences ' % test_count)\n",
    "print('%d validation sequences ' % valid_count)\n",
    "h5f = h5py.File(outfile, 'w')\n",
    "i = 0\n",
    "if train_count > 0:\n",
    "    h5f.create_dataset('train_in'       , data=X[i:i+train_count,:], **compress_args)\n",
    "    h5f.create_dataset('train_out'      , data=y[i:i+train_count], **compress_args)\n",
    "    h5f.create_dataset('train_geneName' , data=geneNames[i:i+train_count].tolist(), **compress_args)\n",
    "    h5f.close()\n",
    "i += train_count\n",
    "if valid_count > 0:\n",
    "    h5f.create_dataset('valid_in'       , data=X[i:i+valid_count,:], **compress_args)\n",
    "    h5f.create_dataset('valid_out'      , data=y[i:i+valid_count], **compress_args)\n",
    "    h5f.create_dataset('valid_geneName' , data=geneNames[i:i+valid_count].tolist(), **compress_args)\n",
    "    h5f.close()\n",
    "i += valid_count\n",
    "if test_count > 0:\n",
    "    h5f.create_dataset('test_in'        , data=X[i:i+test_count,:], **compress_args)\n",
    "    h5f.create_dataset('test_out'       , data=y[i:i+test_count], **compress_args)\n",
    "    h5f.create_dataset('test_geneName'  , data=geneNames[i:i+test_count].tolist(), **compress_args)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "xpresso2.ipynb",
   "provenance": [
    {
     "file_id": "1lhnTcHI3ulwKBkRpTNtIYM7LfqhyEOOe",
     "timestamp": 1544035311191
    },
    {
     "file_id": "1Wovd0PKFd4X5FRcpHTNr3wFppo8iv6CS",
     "timestamp": 1542664140611
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
