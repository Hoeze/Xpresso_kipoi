{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inference.ipynb","provenance":[{"file_id":"1SplqILjJr_ZqXcIUkNIk0tSbthfhYm07","timestamp":1572044421118},{"file_id":"/piper/depot/google3/third_party/py/trax/layers/intro.ipynb","timestamp":1571858674399},{"file_id":"1sF8QbqJ19ZU6oy5z4GUTt4lgUCjqO6kt","timestamp":1569980697572},{"file_id":"1EH76AWQ_pvT4i8ZXfkv-SCV4MrmllEl5","timestamp":1563927451951}],"collapsed_sections":[],"last_runtime":{"build_target":"//learning/deepmind/dm_python:dm_notebook3_tpu","kind":"private"}},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7yuytuIllsv1"},"source":["# Trax Transformer\n","\n","We train **Trax Transformer** on a simple copy problem and run inference.\n","* Training and inference can run on TPU, even with multiple input lengths\n","* Inputs are fed from python but it's asynchronous so doesn't slow training\n","* Transformer in predict mode implements fast inference (attention caches)\n","\n","BEGIN GOOGLE-INTERNAL\n","\n","To use, click Connect, then the Start tab, borg runtime, and select the DeepMind JellyDonut (TPUv2, Python 3) borg runtime type.\n","\n","END GOOGLE-INTERNAL"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BIl27504La0G"},"source":["## General Setup\n","Execute the following few cells (once) before running any of the code samples in this notebook."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oILRLCWN_16u","cellView":"both","outputId":"e35c0885-be75-4752-af89-c34b3b23f149","executionInfo":{"status":"error","timestamp":1577923860424,"user_tz":480,"elapsed":617,"user":{"displayName":"Vikram Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB_g3ycHyXK2wQJuaywzxudHa4XAk3F1LNDGJG9=s64","userId":"13055151899643549382"}},"colab":{"height":324}},"source":["from six.moves import cPickle\n","import os\n","import datetime\n","import random\n","import tempfile\n","from functools import partial\n","import copy\n","\n","import numpy as onp\n","import jax\n","from jax import lax\n","from jax import random as jr\n","from jax import numpy as np\n","from jax.ops import index, index_update\n","\n","from matplotlib import pyplot as plt\n","\n","import tensorflow.google as tf\n","tf.enable_eager_execution()\n","import tensorflow_datasets as tfds\n","\n","from colabtools import adhoc_import\n","with adhoc_import.Google3():\n","  import trax\n","  from trax import trainer_lib\n","  from trax import layers as tl\n","  from trax import inputs as trax_input\n","  from trax import models as trax_models\n","  from trax import optimizers as trax_optimizers\n","  from trax import backend\n","  from trax import shapes\n","  from trax import trainer_lib"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31mImportError:\u001b[0m cannot import name 'trainer_lib'","","If the module is lightweight, try adhoc_import - http://go/adhoc-import\n\nOtherwise, use a custom runtime - http://go/colab-custom-runtime","\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-3-419f6a68a2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0madhoc_import\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGoogle3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[1;32mimport\u001b[0m \u001b[0mtrax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtrax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrainer_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtrax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtrax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrax_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'trainer_lib'"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-LQ89rFFsEdk"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bYWNWL9MJHv9","outputId":"e211df6a-df38-4faa-f9c7-3b57256999b5","executionInfo":{"status":"error","timestamp":1577923780354,"user_tz":480,"elapsed":1537,"user":{"displayName":"Vikram Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB_g3ycHyXK2wQJuaywzxudHa4XAk3F1LNDGJG9=s64","userId":"13055151899643549382"}},"colab":{"height":236}},"source":["def feed_forward(d_model, d_ff, dropout, layer_idx, mode):\n","  \"\"\"Feed-forward block with layer normalization at start.\"\"\"\n","  return tl.Serial(\n","      tl.LayerNorm(),\n","      tl.Dense(d_ff),\n","      tl.Relu(),\n","      tl.Dropout(rate=dropout, name='ff_middle_%d' % layer_idx, mode=mode),\n","      tl.Dense(d_model),\n","      tl.Dropout(rate=dropout, name='ff_final_%d' % layer_idx, mode=mode),\n","  )\n","\n","\n","def encoder_block(d_model, d_ff, n_heads, dropout, layer_idx, mode):\n","  \"\"\"Returns a layer sequence that implements a Transformer encoder block.\n","\n","  The input to the layer sequence is a pair, (activations, mask), where the\n","  mask was created from the original source tokens to prevent attending to the\n","  padding part of the input.\n","\n","  Args:\n","    d_model: int:  depth of embedding\n","    d_ff: int: depth of feed-forward layer\n","    n_heads: int: number of attention heads\n","    dropout: float: dropout rate (how much to drop out)\n","    layer_idx: which layer are we at (for bookkeeping)\n","    mode: str: 'train' or 'eval'\n","\n","  Returns:\n","    A sequence of layers that maps an (activations, mask) pair to an\n","    (activations, mask) pair.\n","  \"\"\"\n","  attention = [\n","      tl.LayerNorm(),\n","      tl.Attention(d_model, n_heads=n_heads, dropout=dropout, mode=mode),\n","      tl.Dropout(rate=dropout, name='enc_attn_dropout', mode=mode),\n","  ]\n","  ff = [\n","      feed_forward(d_model, d_ff, dropout, layer_idx=layer_idx, mode=mode),\n","  ]\n","  return tl.Serial(\n","      tl.Residual(attention),\n","      tl.Residual(ff),\n","  )\n","\n","\n","@tl.layer()\n","def no_padding_mask(x, **kwargs):\n","  del kwargs\n","  return np.reshape(np.ones(x.shape[0]*x.shape[-2], dtype=x.dtype),\n","                    (x.shape[0], 1, 1, x.shape[-2]))\n","\n","\n","def non_tokenizing_transformer(n_classes=57,\n","                               d_model=512,\n","                               d_ff=2048,\n","                               n_layers=6,\n","                               n_heads=8,\n","                               dropout=0.1,\n","                               max_len=1001,\n","                               mode='train'):\n","  \"\"\"Returns a Transformer encoder model.\n","\n","  The input to the model is a tensor of tokens.\n","\n","  Args:\n","    n_classes: how many classes on output\n","    d_model: int:  depth of embedding\n","    d_ff: int: depth of feed-forward layer\n","    n_layers: int: number of encoder/decoder layers\n","    n_heads: int: number of attention heads\n","    dropout: float: dropout rate (how much to drop out)\n","    max_len: int: maximum symbol length for positional encoding\n","    mode: str: 'train' or 'eval'\n","\n","  Returns:\n","    A Transformer model as a layer that maps from a tensor of tokens to\n","    activations over a set of output classes.\n","  \"\"\"\n","  embedder = [\n","      # tl.Embedding(d_model, vocab_size),\n","      tl.Dense(d_model),\n","      tl.Dropout(rate=dropout, name='emb_dropout', mode=mode),\n","      tl.PositionalEncoding(max_len=max_len),\n","  ]\n","  return tl.Serial(                             #      tokens\n","      tl.Dup(),                                 # toks toks\n","      tl.Parallel(embedder, no_padding_mask()),  # vecs mask\n","      [encoder_block(d_model, d_ff, n_heads, dropout, i, mode)\n","       for i in range(n_layers)],               # vecs mask\n","      tl.Parallel([], tl.Drop()),               # ____  0\n","      tl.LayerNorm(),                           # vecs\n","      tl.Mean(axis=1),  # Average on length.    # vecs\n","      tl.Dense(n_classes),                      # vecs\n","  )"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-fcbe13c5c6ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mno_padding_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'tl' is not defined"]}]},{"cell_type":"code","metadata":{"id":"VBMrkP_kkQnX","colab_type":"code","outputId":"ab5ce15e-8dc0-4905-9cec-d946959c78a1","executionInfo":{"status":"error","timestamp":1573669395387,"user_tz":480,"elapsed":80798,"user":{"displayName":"Vikram Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB_g3ycHyXK2wQJuaywzxudHa4XAk3F1LNDGJG9=s64","userId":"13055151899643549382"}},"colab":{"height":426}},"source":["def vikram_inputs(\n","    n_batch=200,\n","    num_input_timestamps=1001,\n","    num_embed=117,\n","    num_output_predictions=57,\n","    cns_path='/readahead/200M/cns/tm-d/home/vikrama/',\n","    n_prefetch=4):\n","  \"\"\"Prepare inputs.\"\"\"\n","\n","  # grab filenames from CNS\n","  test_files = tf.gfile.Glob(os.path.join(cns_path, '*test*'))\n","\n","  # tf.example proto parsing\n","  feature_description = {\n","      'inputs': tf.VarLenFeature(tf.float32),\n","      'targets': tf.VarLenFeature(tf.float32),\n","  }\n","\n","  def _parse_example(x):\n","    return tf.parse_example([x], feature_description)\n","\n","  # reshaping\n","  input_shape = [-1, num_input_timestamps, num_embed]\n","  input_dtype = np.float32\n","  target_shape = [-1, 1, num_output_predictions]\n","  target_dtype = np.float32\n","\n","  def _reshape(x):\n","    inps = x['inputs'].values\n","    inps = tf.reshape(inps, input_shape)\n","    # inps = inps[:, 499:501, :]\n","    tgts = x['targets'].values\n","    tgts = tf.reshape(tgts, target_shape)\n","    return (inps, tgts)\n","\n","  # tf.data chain\n","  def make_dataset_iterator(data_files):\n","    return (  # could have read as numpy directly rather than TFrecords\n","        # pref reads 4 batches into CPU to have queue of input ready\n","        tf.data.TFRecordDataset(data_files)\n","        .map(_parse_example) #removed shuffle layer\n","        .batch(n_batch, drop_remainder=False) #changed from True to False to not drop last batch\n","        .map(_reshape)\n","        .prefetch(n_prefetch)\n","        .as_numpy_iterator()  # converts TFRecord into numpy\n","        )\n","  \n","  return make_dataset_iterator(test_files)\n","\n","# Inference model\n","output_dir = '/cns/tm-d/home/vikrama/rs=6.3/test7/15'\n","\n","predict_model = non_tokenizing_transformer(mode='eval', d_model=512, d_ff=2048, max_len=1001, n_classes=57, n_heads=2, n_layers=8)\n","\n","predict_signature = shapes.ShapeDtype((1, 1001, 117), dtype=np.float32) #shape of input\n","predict_model.initialize_once(predict_signature)\n","\n","# Load from file (API for trainer_state may change)\n","trainer_state = trainer_lib.load_trainer_state(output_dir)\n","predict_model.params = trainer_state.opt_state.weights[0]\n","\n","# Run inference\n","preds = []\n","obs = []\n","inp = []\n","ds_test = vikram_inputs()\n","\n","# make dataset iterators\n","for input in ds_test:\n","  print(input[0].shape)\n","  # inp.append(np.mean(input[0][:,499:501,:], axis=1))\n","  # preds.append(predict_model(input[0], rng=random_key))\n","  # obs.append(np.squeeze(input[1]))\n","preds = np.vstack(preds)\n","obs = np.vstack(obs)\n","inp = np.vstack(inp)\n","\n","print(preds.shape)\n","print(obs.shape)\n","print(inp.shape)\n","\n","from scipy import stats\n","from sklearn import linear_model\n","\n","regr = linear_model.LinearRegression()\n","regr.fit(inp, obs[:,0])\n","y_hat = regr.predict(inp)\n","slope, intercept, r_value, p_value, std_err = stats.linregress(obs[:,0], y_hat)\n","print('BASELINE: Test R^2 = %.3f' % r_value**2)\n","\n","rvalues = []\n","for i in range(0,preds.shape[1]):\n","     slope, intercept, r_value, p_value, std_err = stats.mstats.linregress(preds[:,i], obs[:,i])\n","     print('Test R^2 %d = %.3f' % (i, r_value**2))\n","     rvalues.append(r_value)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model loaded from /cns/tm-d/home/vikrama/rs=6.3/test7/15/model.pkl at step 20000\n","(200, 2, 117)\n","(200, 2, 117)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-8-624f761daf2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m# make dataset iterators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[1;31m# inp.append(np.mean(input[0][:,499:501,:], axis=1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3644\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3640\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3641\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_gpu_py3_vikrama.kernel.vikrama.338279142286.14b334fb3717c109/mount/server/dm_notebook3.par/google3/third_party/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNextSync\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   2470\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"DidnvIa8PpQg","colab_type":"code","outputId":"256fd39c-0bcd-4ede-c400-4aab443dc815","executionInfo":{"status":"ok","timestamp":1573606392081,"user_tz":480,"elapsed":420,"user":{"displayName":"Vikram Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB_g3ycHyXK2wQJuaywzxudHa4XAk3F1LNDGJG9=s64","userId":"13055151899643549382"}},"colab":{"height":34}},"source":["import numpy as np\n","\n","x=np.ones((2,3,3,3))\n","x\n","c=np.reshape(np.ones(x.shape[0]*x.shape[-2], dtype=x.dtype),\n","                    (x.shape[0], 1, 1, x.shape[-2]))\n","\n","c.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 1, 1, 3)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"7yyxRTFSP0kJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}